---
title: 'Summary statistics on the baseline tables for the real data'
author: "Adrian Barnett"
date: "`r format(Sys.time(), '%d %B %Y')`"
output:
  word_document:
    toc: false
    toc_depth: 2
---

```{r setup, include=FALSE}
# using formatting in Word document (see above)
knitr::opts_chunk$set(echo = FALSE, warning=FALSE, message=FALSE, error=FALSE, comment='', dpi=400)
options(width=1000) # Wide pages
options(scipen=999) # avoid scientific presentation
source('99_functions.R') # for roundz
#library(broom) # for regression models
library(janitor) # for tables with totals
library(dplyr)
library(tidyr)
library(stringr)
library(flextable)
library(ggplot2)
library(fitdistrplus) # for fitting gamma distribution to rows
library(xtable)

## get the data; select which source of data to use
sources = c('my_search', 'trialstreamer', 'validation')
source = sources[2]
stage = 'model' # also works for summary
source('1_which_data_source.R') # uses `source` and `stage`
```

# Exclusions

## Exclusions prior to reading data

From the 10,000 original papers.

```{r}
# tidy up reasons
excluded = mutate(excluded,
      reason = case_when(
        reason == 'Table is graphic' ~ "No baseline table", # cannot separate these
        reason == 'Not an RCT' ~ "Not a randomised trial",
        reason == 'Complex format' ~ 'Difficult layout', # merge with this reason
        TRUE ~ as.character(reason) # otherwise
      ))
#
tab = tabyl(excluded, reason) %>%
  arrange(-n) %>%
  adorn_totals("row") %>%
  adorn_pct_formatting() 
excluded_tab = flextable(tab) %>%
  theme_box() %>%
  autofit()
excluded_tab
# export to latex
#print(xtable(tab, digits = c(0,0,0,0)), include.rownames=FALSE)
```

## Exclusions from data that could be read in

```{r}
excluded_rows = flextable(excluded_counts) %>%
  theme_box() %>%
  autofit()
excluded_rows
```

The table shows the number of excluded rows of data, apart from the "Algorithm error" row which is the total number of excluded studies.

The total number of included studies was `r length(unique(table_data$pmcid))` with `r format(nrow(table_data), big.mark=',')` rows.

<!--- Some results were changed in the processing step: --->

```{r}
# Not worth presenting, all part of the algorithm
tab = tabyl(dat=table_data , var1='changed') %>%
  adorn_totals() %>%
  mutate(percent = round(percent*100))
ftab = flextable(tab) %>%
  theme_box() %>%
  autofit()
```

# Number of summary statistics (rows) per table

```{r, include=FALSE}
rows = group_by(table_data, pmcid) %>%
  summarise(row = max(row),
            col = max(column)) %>%
  ungroup()
# add distribution curve using best-fitting gamma distribution
fg = fitdist(data=rows$row, distr="gamma") # spits stuff to screen
max_row = max(rows$row)
N = nrow(rows)
pred = dgamma(x=1:max_row, shape=fg$estimate[1], rate=fg$estimate[2])
gamma_line = data.frame(row = 1:max_row, fitted = pred*N)
```

```{r}
#
gplot_rows = ggplot(data=rows, aes(x=row))+
  geom_bar(fill='skyblue', col='grey33') +
  geom_line(data=gamma_line, aes(x=row, y=fitted), col='dark red')+
  ylab('Count')+
  xlab('Number of table rows')+
  theme_bw()
gplot_rows

# save for paper supplement
mean_row = mean(rows$row)
save(gplot_rows, mean_row, fg, file='results/gamma_rows.RData')
```

The mean number of rows per table was `r round(mean_row,0)`. The red line shows a gamma distribution with a shape parameter of `r roundz(fg$estimate[1],1)` and rate of `r roundz(fg$estimate[2],2)`.

# Sample sizes

### Histogram of sample size per group

```{r, include=FALSE}
# unique sample size per column and trial
sizes = dplyr::select(table_data, pmcid, column, sample_size) %>%
  unique()
# add distribution curve using best-fitting gamma distribution
fg = fitdist(data=log(sizes$sample_size), distr="gamma") # spits stuff to screen, so include=FALSE
max_size = 10^5
N = nrow(sizes)
x = seq(2, 10000, length.out=N)
pred = dgamma(x=log(x), shape=fg$estimate[1], rate=fg$estimate[2]) # must be log
gamma_line = data.frame(sample_size = x, fitted = 0.4*pred*N)
```

```{r}
#
gplot_sample = ggplot(data=sizes, aes(x=sample_size))+
  geom_histogram(fill='skyblue3', col='grey33')+
  geom_line(data=gamma_line, aes(x=sample_size, y=fitted), col='dark red')+
  scale_x_log10()+
  xlab('Sample size (log-e)')+
  ylab('Count')+
  theme_bw() +
  theme(panel.grid.minor = element_blank())
gplot_sample
# save for paper supplement
mean_size = mean(sizes$sample_size)
save(gplot_sample, mean_size, fg, file='results/gamma_sizes.RData')
```

The gamma distribution (red line) fitted to the log-transformed (base e) sample size has a shape parameter of `r roundz(fg$estimate[1],1)` and rate of `r roundz(fg$estimate[2],2)`.

### Summary statistics for sample size per group

```{r}
#
probs = c(0.05,0.25,0.5,0.75,0.95)
tab = summarise(sizes, 
                sample = round(quantile(sample_size, probs)))
tab = bind_cols(probs, tab)
names(tab)[1] = 'percentile'
ftab = flextable(tab) %>%
  theme_box() %>%
  autofit()
ftab
```

The table shows the sample size for five percentiles. This is for the sample size per group.

# Number of groups (columns) per table

```{r}
gplot = ggplot(data=rows, aes(x=col))+
  geom_bar(fill='indianred') +
  scale_x_continuous(breaks=2:10)+
  ylab('Count')+
  xlab('Number of groups')+
  theme_bw()
gplot
```

# Frequency table of statistics

```{r}
table = table_data %>% tabyl(statistic) %>%
  arrange(-n) %>% # high to low
  adorn_totals("row") %>%
  mutate(percent = round(percent*100)) %>%
  mutate(included = case_when(
    statistic == 'percent' ~ 'Yes',
    statistic == 'continuous' ~ 'Yes',
    statistic == 'numbers' ~ 'Yes',
    statistic == 'ci' ~ 'Yes',
    statistic == 'Total' ~ ' ', # for ordering
    TRUE ~ 'No'
  ),
  statistic = str_to_sentence(statistic), # Upper case first letter
  statistic = ifelse(statistic=='Ci', 'Confidence interval', statistic),
  statistic = ifelse(statistic=='Pvals', 'P-values', statistic),
  statistic = ifelse(statistic=='Min_max', 'Range', statistic)) %>%
  dplyr::select(included, statistic, n, percent) %>%
  arrange(desc(included), desc(n)) %>%
  rename('Included' = 'included',
         'Statistic' = 'statistic')
ftab_stats = flextable(table) %>%
  theme_box() %>%
  merge_v(j=1) %>%
  colformat_num(j=2, big.mark=',', digits=0) %>%
  autofit()
ftab_stats
#print(xtable(table), include.rownames=FALSE)
```

# About the papers

## Dates

```{r}
date_tab = filter(design, !is.na(date)) %>%
  mutate(daten = as.numeric(date)) %>%
  summarise(Q1 = quantile(daten, 0.25),
            median = quantile(daten, 0.5),
            Q3 = quantile(daten, 0.75)) %>%
  mutate(Q1 = as.Date(Q1, origin='1970-01-01'),
         median = as.Date(median, origin='1970-01-01'),
         Q3 = as.Date(Q3, origin='1970-01-01'))
date_tab
```

## Top ten journals

```{r}
tab = group_by(design, journal) %>%
  tally() %>%
  arrange(-n) %>%
  slice(1:10)
journal_tab = flextable(tab) %>%
  theme_box() %>%
  autofit()
journal_tab
```

In total there were `r length(unique(design$journal))` journals.

## Top ten countries

```{r}
tab = group_by(design, affiliation) %>%
  tally() %>%
  arrange(-n) %>%
  slice(1:10)
country_tab = flextable(tab) %>%
  theme_box() %>%
  autofit()
country_tab
```

In total there were `r length(unique(design$affiliation))` countries. The country was based on the affiliation of the first author.

## Study design features

```{r}
features = dplyr::select(design, pmcid, rct, cluster, pilot, block_randomisation, adaptive_randomisation, sem) %>%
  reshape2::melt(id= 'pmcid') %>%
  group_by(variable) %>%
  summarise(N = n(), Yes = sum(value)) %>%
  mutate(percent = roundz(100*Yes/N)) %>%
  ungroup() %>%
  arrange(-Yes) %>%
  rename('Study design' = 'variable')
ftab = flextable(features) %>%
  theme_box() %>%
  autofit()
ftab
```

The variables are based on mentions in the text as follows:

-   rct = RCT or versions of "randomised controlled trial" in the title or abstract
-   block_randomisation = "block" and versions of "randomisation" within 5 words of each other anywhere in paper
-   adaptive randomisation = "adaptive randomisation" anywhere in paper
-   cluster = "cluster\*" in title or abstract
-   pilot = "pilot" in title
-   sem = "SE", "SEM" or "standard error" in baseline table or footnote

# P-values

Here we examine the number of trials that included p-values in the table or text.

```{r}
# Use function as repeated below
make_pvals = function(indata){
tab = mutate(indata, 
    in_table = factor(as.numeric(in_table), levels=0:1, labels=c('No','Yes')),
    in_text = factor(as.numeric(in_text), levels=0:1, labels=c('No','Yes'))) %>%
  group_by(in_table, in_text) %>%
  tally() %>%
  ungroup() %>%
  mutate(percent = 100* n/sum(n),
         cell = paste(n, ' (', roundz(percent,0), ')', sep=''),
         in_text = as.character(in_text),
         in_text = ifelse(is.na(in_text), 'Missing', in_text)) %>%
  dplyr::select(in_table, in_text, cell) %>%
  rename('In table' = 'in_table',
         'In text' = 'in_text',
         'n (%)' = 'cell')
pval_tab = flextable(tab) %>%
  theme_box() %>%
  merge_v(j=1) %>%
  autofit()
} # end of function
pval_tab = make_pvals(pvalues)
pval_tab

# overall table or text
overall = mutate(pvalues, either = in_text==TRUE | in_table ==TRUE) %>%
  summarise(n = n(), r = sum(either, na.rm = TRUE))
overall_ci = with(overall, binom.test(x=r, n=n)) # exact binomial
overall_pval = data.frame(mean = round(overall_ci$estimate*100),
                     lower = round(overall_ci$conf.int[1]*100),
                     upper = round(overall_ci$conf.int[2]*100))
# simple results for text
overall = summarise(pvalues, n = n(), r = sum(in_text, na.rm = TRUE))
overall_ci = with(overall, binom.test(x=r, n=n)) 
table_pval = data.frame(mean = round(overall_ci$estimate*100),
                     lower = round(overall_ci$conf.int[1]*100),
                     upper = round(overall_ci$conf.int[2]*100))
```

The results are missing for the table check where there was no text that refered to the table.

The overall percentage of trials where p-values were mentioned in the table only was `r table_pval$mean`% with a 95% CI from `r table_pval$lower`% to `r table_pval$upper`%.

The overall percentage of trials where p-values were mentioned in the text or table was `r overall_pval$mean`% with a 95% CI from `r overall_pval$lower`% to `r overall_pval$upper`%.

### Excluding cluster-randomised trials

We repeat the above table after excluding cluster-randomised trials.

```{r}
pvalues = left_join(pvalues, design, by='pmcid') 
n_cluster = sum(pvalues$cluster, na.rm=TRUE) # count the number of cluster RCTs
pvalues = filter(pvalues, cluster == FALSE)
pval_tab_cluster = make_pvals(pvalues)
pval_tab_cluster
# simple results for text
overall = summarise(pvalues, n = n(), r = sum(in_text, na.rm = TRUE))
overall_ci = with(overall, binom.test(x=r, n=n)) 
table_pval_no_cluster = data.frame(mean = round(overall_ci$estimate*100),
                     lower = round(overall_ci$conf.int[1]*100),
                     upper = round(overall_ci$conf.int[2]*100))
```

Excluding the `r sum(design$cluster)` cluster-randomised trials made little differences to the percentages.

# Decimal places

Below we examine the number of decimal places for continuous variables. When researchers use few decimal places then the comparison between groups can appear under-dispersed. The results are stratified based on the size of the mean as larger means required fewer decimal places. The cells show the decimal place quantiles at 10, 25, 50 (median), 75 and 90.

```{r}
# group by absolute mean
dp_stats = filter(table_data, statistic=='continuous') %>%
  dplyr::select(pmcid, stat1, stat2, dp1, dp2) %>%
  mutate(stat1 = abs(stat1),  # absolute
         stat1g = cut(stat1 , breaks=c(0,10,100,1000,Inf), scientific=FALSE, right=FALSE)) %>%
  group_by(stat1g) %>%
  summarise(n = n(),
            q10 = quantile(dp1, 0.10),
            q25 = quantile(dp1, 0.25),
            q50 = median(dp1),
            q75 = quantile(dp1, 0.75),
            q90 = quantile(dp1, 0.90)) %>%
  ungroup() %>%
  rename('Range for mean' = 'stat1g')
ftab = flextable(dp_stats) %>%
  autofit() %>%
  theme_box()
ftab
```

```{r, include=FALSE}
# save for paper and supplement
save(country_tab, journal_tab, table_pval, n_cluster, table_pval_no_cluster, overall_pval, pval_tab, excluded_tab, excluded_rows, ftab_stats, file='results/summary_stats.RData')
```
